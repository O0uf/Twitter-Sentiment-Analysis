{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e97962",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9f479",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "this copy is for saving intermediate step: preprocessing steps combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dceca3f",
   "metadata": {},
   "source": [
    "### Loads Data & Packages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8306553a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "# Preprocessing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML models\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7016d028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b98f16",
   "metadata": {},
   "source": [
    "- `textID` - unique ID for each piece of text\n",
    "- `text` - the text of the tweet\n",
    "- `sentiment` - the general sentiment of the tweet\n",
    "- `selected_text` - [train only] the text that supports the tweet's sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce13cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_of_data(data):\n",
    "    total=data.isnull().sum().sort_values(ascending=False)\n",
    "    percentage=round(total/data.shape[0]*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd5c4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selected_text</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Total  Percentage\n",
       "text               1         0.0\n",
       "selected_text      1         0.0\n",
       "textID             0         0.0\n",
       "sentiment          0         0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_of_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d35a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicated_values_data(data):\n",
    "    dup=[]\n",
    "    columns=data.columns\n",
    "    for i in data.columns:\n",
    "        dup.append(sum(data[i].duplicated()))\n",
    "    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90695b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9d68a_row0_col1, #T_9d68a_row1_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9d68a_row2_col1 {\n",
       "  background-color: #e6e5f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9d68a_row3_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9d68a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Columns</th>\n",
       "      <th class=\"col_heading level0 col1\" >Duplicate count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9d68a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9d68a_row0_col0\" class=\"data row0 col0\" >textID</td>\n",
       "      <td id=\"T_9d68a_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d68a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9d68a_row1_col0\" class=\"data row1 col0\" >text</td>\n",
       "      <td id=\"T_9d68a_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d68a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9d68a_row2_col0\" class=\"data row2 col0\" >selected_text</td>\n",
       "      <td id=\"T_9d68a_row2_col1\" class=\"data row2 col1\" >5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d68a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9d68a_row3_col0\" class=\"data row3 col0\" >sentiment</td>\n",
       "      <td id=\"T_9d68a_row3_col1\" class=\"data row3 col1\" >27478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbd254ac1c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_values_data(train).style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08909822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_dist_overview(data,col):\n",
    "    total = data.loc[:,col].value_counts()\n",
    "    freq = data.loc[:,col].value_counts(normalize=True)\n",
    "    return pd.concat([total, freq],axis=1,keys=[\"Count\",\"Frequency\"]\n",
    "                    ).style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a29865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9df8b_row0_col0, #T_9df8b_row0_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9df8b_row1_col0, #T_9df8b_row1_col1 {\n",
       "  background-color: #dcdcec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9df8b_row2_col0, #T_9df8b_row2_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9df8b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Count</th>\n",
       "      <th class=\"col_heading level0 col1\" >Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9df8b_level0_row0\" class=\"row_heading level0 row0\" >neutral</th>\n",
       "      <td id=\"T_9df8b_row0_col0\" class=\"data row0 col0\" >11118</td>\n",
       "      <td id=\"T_9df8b_row0_col1\" class=\"data row0 col1\" >0.404570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df8b_level0_row1\" class=\"row_heading level0 row1\" >positive</th>\n",
       "      <td id=\"T_9df8b_row1_col0\" class=\"data row1 col0\" >8582</td>\n",
       "      <td id=\"T_9df8b_row1_col1\" class=\"data row1 col1\" >0.312288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df8b_level0_row2\" class=\"row_heading level0 row2\" >negative</th>\n",
       "      <td id=\"T_9df8b_row2_col0\" class=\"data row2 col0\" >7781</td>\n",
       "      <td id=\"T_9df8b_row2_col1\" class=\"data row2 col1\" >0.283141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbd281bc520>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dist_overview(train,'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6589609d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Distribution of Sentiment')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='sentiment',data=train).set(title='Distribution of Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5786dd4",
   "metadata": {},
   "source": [
    "### Clean Texts\n",
    "- remove punctuation\n",
    "- to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d533b42",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove text in brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) #remove link\n",
    "    text = re.sub('<.*?>+', '', text) \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eee0fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_text = train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b6aef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                I`d have responded, if I were going\n",
       "1      Sooo SAD I will miss you here in San Diego!!!\n",
       "2                          my boss is bullying me...\n",
       "3                     what interview! leave me alone\n",
       "4   Sons of ****, why couldn`t they put them on t..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ori_text.to_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650968a",
   "metadata": {},
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e09b91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree = \"\".join([c for c in str(text) if c not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "df['no_punc']= df['text'].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6d8a8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of  why couldnt they put them on the rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                             no_punc  \n",
       "0                  Id have responded if I were going  \n",
       "1         Sooo SAD I will miss you here in San Diego  \n",
       "2                             my boss is bullying me  \n",
       "3                      what interview leave me alone  \n",
       "4   Sons of  why couldnt they put them on the rel...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f9a75",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Tokenize & To lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5507bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['tokens'] = df['no_punc'].apply(lambda x:tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c485d",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aba47f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(x):\n",
    "    return [y for y in x if y not in stopwords.words('english')]\n",
    "df['no_stop'] = df['tokens'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef24b23",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be668d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    return [lemmatizer.lemmatize(x) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ad7ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['no_stop'].apply(lambda text:lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d231bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stop</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>[bos, bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "      <td>[son, couldnt, put, release, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                             no_punc  \\\n",
       "0                  Id have responded if I were going   \n",
       "1         Sooo SAD I will miss you here in San Diego   \n",
       "2                             my boss is bullying me   \n",
       "3                      what interview leave me alone   \n",
       "4   Sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0          [id, have, responded, if, i, were, going]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                       [my, boss, is, bullying, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "\n",
       "                                           no_stop  \\\n",
       "0                           [id, responded, going]   \n",
       "1                    [sooo, sad, miss, san, diego]   \n",
       "2                                 [boss, bullying]   \n",
       "3                        [interview, leave, alone]   \n",
       "4  [sons, couldnt, put, releases, already, bought]   \n",
       "\n",
       "                                         cleaned  \n",
       "0                         [id, responded, going]  \n",
       "1                  [sooo, sad, miss, san, diego]  \n",
       "2                                [bos, bullying]  \n",
       "3                      [interview, leave, alone]  \n",
       "4  [son, couldnt, put, release, already, bought]  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59030665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bos, bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[son, couldnt, put, release, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned\n",
       "0                         [id, responded, going]\n",
       "1                  [sooo, sad, miss, san, diego]\n",
       "2                                [bos, bullying]\n",
       "3                      [interview, leave, alone]\n",
       "4  [son, couldnt, put, release, already, bought]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = pd.DataFrame(df['cleaned'])\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49e98027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned.to_csv('cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e1a2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['cleaned'] = cleaned['cleaned'].apply(lambda txt:\" \".join(c for c in txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1650a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean'] = cleaned['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2f042dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "      <td>id responded going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>0</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>0</td>\n",
       "      <td>bos bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>0</td>\n",
       "      <td>interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>0</td>\n",
       "      <td>son couldnt put release already bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  sentiment  \\\n",
       "0  I`d have responded, if I were going          1   \n",
       "1                             Sooo SAD          0   \n",
       "2                          bullying me          0   \n",
       "3                       leave me alone          0   \n",
       "4                        Sons of ****,          0   \n",
       "\n",
       "                                    clean  \n",
       "0                      id responded going  \n",
       "1                 sooo sad miss san diego  \n",
       "2                            bos bullying  \n",
       "3                   interview leave alone  \n",
       "4  son couldnt put release already bought  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eaea8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {\n",
    "    'negative' : 0,\n",
    "    'neutral' : 1,\n",
    "    'positive' : 2\n",
    "}\n",
    "train['sentiment'] = train['sentiment'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b40af",
   "metadata": {},
   "source": [
    "## Combined Preprocessing Function\n",
    "\n",
    "Now we combine the preprocessing steps into one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a0d27638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_preproc(df,column,now):\n",
    "    \"\"\"Preprocessing for df[column]\n",
    "        process involved: \n",
    "            - remove punctuation\n",
    "            - lower case\n",
    "            - tokenize & remove stop word \n",
    "            - lemmatize (lemma or stem)\n",
    "    \"\"\"\n",
    "    # remove punctutation\n",
    "    def remove_punctuation(text):\n",
    "        punctuationfree = \"\".join([c for c in str(text) if c not in string.punctuation])\n",
    "        return punctuationfree\n",
    "    df[now]= df[column].apply(lambda x:remove_punctuation(x))\n",
    "    \n",
    "    # Tokenize & to lower case\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df[now] = df[now].apply(lambda x:tokenizer.tokenize(x.lower()))\n",
    "\n",
    "    def remove_stopword(x):\n",
    "        return [y for y in x if y not in stopwords.words('english')]\n",
    "    df[now] = df[now].apply(lambda x:remove_stopword(x))\n",
    "    \n",
    "    # lemmatize and join the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def sentence_lemmatize(text):\n",
    "        return \" \".join([lemmatizer.lemmatize(x) for x in text])\n",
    "    df[now] = df[now].apply(lambda text:sentence_lemmatize(text))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = twit_preproc(df,'text','cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef852262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

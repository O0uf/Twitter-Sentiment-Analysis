{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c9f479",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "[CheatSheet](https://www.kaggle.com/code/raenish/cheatsheet-text-helper-functions/notebook)\n",
    "\n",
    "Data Source: [kaggle](https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset?select=Twitter_Data.csv)\n",
    "This set of tweets is politics related.\n",
    "\n",
    "In this notebook we will explore doc2vec(DBOW&DM).\n",
    "\n",
    "Some readings I found helpful:\n",
    "  - Introduction to Doc2Vec [link](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)\n",
    "  - Understand Wrod2Vec [link](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "  - Sentiment Analysis Series by Kim [link](https://medium.com/towards-data-science/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74)\n",
    "\n",
    "This project is not completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665e4ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import data & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9ce45d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from time import time\n",
    "# Preprocessing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "import nltk\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classfication_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0117c",
   "metadata": {},
   "source": [
    "# Preprocessing Text \n",
    "<a id=\"1\"></a>\n",
    "Usually the steps includes \n",
    "\n",
    "1. Scrape text from raw documents\n",
    "2. remove punctuation\n",
    "3. lower case\n",
    "4. tokenize & remove stop word \n",
    "5. lemmatize (lemma or stem)\n",
    "\n",
    "This is a semi cleaned dataset,so some of the preprocessing is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0a63a4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def twit_preproc(df,column,now, tokenized=True):\n",
    "    \"\"\"Preprocessing for df[column]\n",
    "        process involved: \n",
    "            - remove punctuation\n",
    "            - lower case\n",
    "            - tokenize & remove stop word \n",
    "            - lemmatize (lemma or stem)\n",
    "            - optional: joining the tokens in each corpus\n",
    "        the cleaned column will be in df[now]\n",
    "        \n",
    "    \"\"\"\n",
    "    def clean_text(text):\n",
    "        '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "        text = str(text).lower()\n",
    "        text = re.sub('\\[.*?\\]', '', text) # remove text in brackets\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text) #remove link\n",
    "        text = re.sub('<.*?>+', '', text) \n",
    "        #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', '', text) #remove numbers\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        return text\n",
    "    df[now]= df[column].apply(lambda x:clean_text(x))\n",
    "    \n",
    "    # Tokenize & to lower case\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df[now] = df[now].apply(lambda x:tokenizer.tokenize(x))\n",
    "\n",
    "    def remove_stopword(x):\n",
    "        return [y for y in x if y not in stopwords.words('english')]\n",
    "    df[now] = df[now].apply(lambda x:remove_stopword(x))\n",
    "    \n",
    "    # lemmatize and join the words\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #def sentence_lemmatize(text):\n",
    "    #    return ([lemmatizer.lemmatize(x) for x in text])\n",
    "    #df[now] = df[now].apply(lambda text:sentence_lemmatize(text))\n",
    "    \n",
    "    # join the text \n",
    "    if (not tokenized):\n",
    "        df[now] = df[now].apply(lambda text: \" \".join(x for x in text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeefbd",
   "metadata": {},
   "source": [
    "### Reads data\n",
    "- `category`: sentiment\n",
    "    - -1 = Negative\n",
    "    - 0 = Neutral\n",
    "    - 1 = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6760e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_2/Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f726bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[modi, promised, minimum, government, maximum,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[talk, nonsense, continue, drama, vote, modi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[say, vote, modi, welcome, bjp, told, rahul, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[asking, supporters, prefix, chowkidar, names,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[answer, among, powerful, world, leader, today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[crores, paid, neerav, modi, recovered, congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[dear, rss, terrorist, payal, gawar, modi, kil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cover, interaction, forum, left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[big, project, came, india, modi, dream, proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ever, listen, like, gurukul, discipline, main...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category  \\\n",
       "0       when modi promised “minimum government maximum...      -1.0   \n",
       "1       talk all the nonsense and continue all the dra...       0.0   \n",
       "2       what did just say vote for modi  welcome bjp t...       1.0   \n",
       "3       asking his supporters prefix chowkidar their n...       1.0   \n",
       "4       answer who among these the most powerful world...       1.0   \n",
       "...                                                   ...       ...   \n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0   \n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0   \n",
       "162977  did you cover her interaction forum where she ...       0.0   \n",
       "162978  there big project came into india modi dream p...       0.0   \n",
       "162979  have you ever listen about like gurukul where ...       1.0   \n",
       "\n",
       "                                                     text  \n",
       "0       [modi, promised, minimum, government, maximum,...  \n",
       "1           [talk, nonsense, continue, drama, vote, modi]  \n",
       "2       [say, vote, modi, welcome, bjp, told, rahul, m...  \n",
       "3       [asking, supporters, prefix, chowkidar, names,...  \n",
       "4       [answer, among, powerful, world, leader, today...  \n",
       "...                                                   ...  \n",
       "162975  [crores, paid, neerav, modi, recovered, congre...  \n",
       "162976  [dear, rss, terrorist, payal, gawar, modi, kil...  \n",
       "162977                  [cover, interaction, forum, left]  \n",
       "162978  [big, project, came, india, modi, dream, proje...  \n",
       "162979  [ever, listen, like, gurukul, discipline, main...  \n",
       "\n",
       "[162980 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_preproc(df,'clean_text','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12716588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118782</th>\n",
       "      <td>watch shri narendra modis exclusive interview ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>watch shri narendra modis exclusive interview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77023</th>\n",
       "      <td>there nothing against modi attack then personal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nothing modi attack personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62407</th>\n",
       "      <td>nothing new modi just ribbon cutting mms work ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nothing new modi ribbon cutting mms work busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136902</th>\n",
       "      <td>mumbai march —setting the campaign tone for th...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>mumbai march setting campaign tone lok sabha e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137403</th>\n",
       "      <td>you want say that impossible that congress ind...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>want say impossible congress indulged corrupti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category  \\\n",
       "118782  watch shri narendra modis exclusive interview ...       0.0   \n",
       "77023     there nothing against modi attack then personal       0.0   \n",
       "62407   nothing new modi just ribbon cutting mms work ...      -1.0   \n",
       "136902  mumbai march —setting the campaign tone for th...      -1.0   \n",
       "137403  you want say that impossible that congress ind...      -1.0   \n",
       "\n",
       "                                                     text  \n",
       "118782  watch shri narendra modis exclusive interview ...  \n",
       "77023                        nothing modi attack personal  \n",
       "62407   nothing new modi ribbon cutting mms work busin...  \n",
       "136902  mumbai march setting campaign tone lok sabha e...  \n",
       "137403  want say impossible congress indulged corrupti...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df,test_size=0.1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0480cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 146672 rows, and testing set has 16297 rows\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "print(\"Training set has {} rows, and testing set has {} rows\".\n",
    "     format(train.shape[0],test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b4c2c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118782    watch shri narendra modis exclusive interview ...\n",
       "77023                          nothing modi attack personal\n",
       "62407     nothing new modi ribbon cutting mms work busin...\n",
       "136902    mumbai march setting campaign tone lok sabha e...\n",
       "137403    want say impossible congress indulged corrupti...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,x_test = train['text'],test['text']\n",
    "y,y_test = train['category'],test['category']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245c7a4",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4a910",
   "metadata": {},
   "source": [
    "### DBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a6c1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4627667",
   "metadata": {},
   "source": [
    "Doc2Vec require each of its input to be a TaggedDocument (a list of words and a list of label) \n",
    "```\n",
    "# EXAMPLE\n",
    "str01 = \"dog love cat\"\n",
    "TaggedDocument(str01.split(),'H1')\n",
    "```\n",
    "\\>>> str01 = `TaggedDocument(words=['dog', 'love', 'cat'], tags=['H1'])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dca18708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_corpus(tweets,label_head=\"TAG\"):\n",
    "    \"\"\"\n",
    "    Returns a list of TaggedDocument object with the tags = 'label_index'\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i,tweet in enumerate(tweets):\n",
    "        result.append(TaggedDocument(tweet.split(), [label_head + '_' + str(i)]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd945c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tagged = tag_corpus(X,\"TRAIN\")\n",
    "test_tagged = tag_corpus(x_test,\"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f7ed776",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tagged = X_tagged + test_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589f227",
   "metadata": {},
   "source": [
    "\n",
    "`vector_size` is the dimension of the output layer (as well as hidden layer). It is a hypter parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b5c0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbow_model = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "dbow_model.build_vocab([x for x in all_tagged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80adfbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 45.2 s, total: 5min 27s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    dbow_model.train(utils.shuffle([x for x in all_tagged]), total_examples=len(all_tagged), epochs=1)\n",
    "    dbow_model.alpha -= 0.002\n",
    "    dbow_model.min_alpha = dbow_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1290f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vectors from model \n",
    "def get_vectors(model, corpus_size, vectors_size, label):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = label + '_' + str(i)\n",
    "        vectors[i] = model.dv[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(dbow_model, len(X_tagged), 300, 'TRAIN')\n",
    "test_vectors_dbow = get_vectors(dbow_model, len(test_tagged), 300, 'TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5b4bf",
   "metadata": {},
   "source": [
    "### DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6a0549c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmc_model = Doc2Vec(dm=1, dm_concat=1, vector_size=300, window=2, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "dmc_model.build_vocab([x for x in all_tagged])\n",
    "\n",
    "for epoch in range(30):\n",
    "    dmc_model.train(utils.shuffle([x for x in all_tagged]), total_examples=len(all_tagged), epochs=1)\n",
    "    dmc_model.alpha -= 0.002\n",
    "    dmc_model.min_alpha = dmc_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0c711c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(dmc_model, len(X_tagged), 300, 'TRAIN')\n",
    "test_vectors_dbow = get_vectors(dmc_model, len(test_tagged), 300, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "22328da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for DBOW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.64      0.09      0.15      3494\n",
      "         0.0       0.35      0.20      0.26      5578\n",
      "         1.0       0.46      0.80      0.58      7225\n",
      "\n",
      "    accuracy                           0.44     16297\n",
      "   macro avg       0.48      0.36      0.33     16297\n",
      "weighted avg       0.46      0.44      0.38     16297\n",
      "\n",
      "CPU times: user 1min 46s, sys: 4.84 s, total: 1min 51s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlr = mlr.fit(train_vectors_dbow,y)\n",
    "preds = mlr.predict(test_vectors_dbow)\n",
    "print(\"Model Accuracy for DBOW\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484db43",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<a id=\"4\"></a>\n",
    "As we decided in previous notebook, the model we will use is logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d54db327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "mlr = LogisticRegression(max_iter=500, multi_class='multinomial',solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f874622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 955 ms, total: 16.2 s\n",
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlr = mlr.fit(train_vectors_dbow,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b99bb925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for DBOW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.51      0.31      0.38      3494\n",
      "         0.0       0.60      0.63      0.62      5578\n",
      "         1.0       0.60      0.70      0.65      7225\n",
      "\n",
      "    accuracy                           0.59     16297\n",
      "   macro avg       0.57      0.54      0.55     16297\n",
      "weighted avg       0.58      0.59      0.58     16297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = mlr.predict(test_vectors_dbow)\n",
    "print(\"Model Accuracy for DBOW\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d0a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

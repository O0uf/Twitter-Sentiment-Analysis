{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c9f479",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "[CheatSheet](https://www.kaggle.com/code/raenish/cheatsheet-text-helper-functions/notebook)\n",
    "\n",
    "Data Source: [Sentiment140](http://help.sentiment140.com/for-students)\n",
    "\n",
    "In this notebook we will tune our LR model, and we also use a larger and more general set of data.\n",
    "\n",
    "Some readings I found helpful:\n",
    "  - GridSearchCV [link](https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/)\n",
    "  - Sentiment Analysis Series by Kim [link](https://medium.com/towards-data-science/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74)\n",
    "  - Mathmatical Intuition to Logistic Regression [link](https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665e4ac",
   "metadata": {},
   "source": [
    "## Import data & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad9ce45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeefbd",
   "metadata": {},
   "source": [
    "### Reads data\n",
    "\n",
    "* 0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* 1 - the id of the tweet (2087)\n",
    "* 2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* 3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* 4 - the user that tweeted (robotickilldozr)\n",
    "* 5 - the text of the tweet (Lyx is cool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6760e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset does not have column names, so we need to define it \n",
    "cols = [str(i) for i in range(6)]\n",
    "df = pd.read_csv('data/sent140/140noemoticon.csv', encoding='latin-1',names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9abd5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['0','5']]\n",
    "df = df.rename(mapper={'0':'target','5':'text'},axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6268635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset has 1600000 entries\n"
     ]
    }
   ],
   "source": [
    "print(\"The original dataset has {} entries\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0117c",
   "metadata": {},
   "source": [
    "# Preprocessing Text \n",
    "<a id=\"1\"></a>\n",
    "Usually the steps includes \n",
    "\n",
    "1. Scrape text from raw documents\n",
    "2. remove punctuation\n",
    "3. lower case\n",
    "4. tokenize & remove stop word \n",
    "5. lemmatize (lemma or stem)\n",
    "\n",
    "We use lemmatize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0a63a4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def twit_preproc(df,column,now, tokenized=False):\n",
    "    \"\"\"Preprocessing for df[column]\n",
    "        process involved: \n",
    "            - remove punctuation\n",
    "            - lower case\n",
    "            - tokenize & remove stop word \n",
    "            - lemmatize (lemma or stem)\n",
    "            - optional: joining the tokens in each corpus\n",
    "        the cleaned column will be in df[now]\n",
    "        \n",
    "    \"\"\"\n",
    "    def clean_text(text):\n",
    "        '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "        text = str(text).lower()\n",
    "        text = re.sub('\\[.*?\\]', '', text) \n",
    "        text = re.sub('<.*?>+', '', text) # remove text in brackets\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove link\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', '', text) #remove numbers\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        return text\n",
    "    df[now]= df[column].apply(lambda x:clean_text(x))\n",
    "    \n",
    "    # Tokenize & to lower case\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df[now] = df[now].apply(lambda x:tokenizer.tokenize(x))\n",
    "\n",
    "    def remove_stopword(x):\n",
    "        return [y for y in x if y not in stopwords.words('english')]\n",
    "    df[now] = df[now].apply(lambda x:remove_stopword(x))\n",
    "    \n",
    "    # lemmatize and join the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def sentence_lemmatize(text):\n",
    "        return ([lemmatizer.lemmatize(x) for x in text])\n",
    "    df[now] = df[now].apply(lambda text:sentence_lemmatize(text))\n",
    "    \n",
    "    # join the text \n",
    "    if (tokenized == False):\n",
    "        df[now] = df[now].apply(lambda text: \" \".join(x for x in text))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98f726bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min, sys: 8min 46s, total: 41min 47s\n",
      "Wall time: 42min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot awww thats bummer shoulda got david...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many time ball managed save res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdbcom cool hear old walt interview â</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happy birthday boo alll time tupac amaru shakur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0             0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1             0  is upset that he can't update his Facebook by ...   \n",
       "2             0  @Kenichan I dived many times for the ball. Man...   \n",
       "3             0    my whole body feels itchy and like its on fire    \n",
       "4             0  @nationwideclass no, it's not behaving at all....   \n",
       "...         ...                                                ...   \n",
       "1599995       4  Just woke up. Having no school is the best fee...   \n",
       "1599996       4  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997       4  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998       4  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999       4  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                clean_text  \n",
       "0        switchfoot awww thats bummer shoulda got david...  \n",
       "1        upset cant update facebook texting might cry r...  \n",
       "2        kenichan dived many time ball managed save res...  \n",
       "3                          whole body feel itchy like fire  \n",
       "4                 nationwideclass behaving im mad cant see  \n",
       "...                                                    ...  \n",
       "1599995                      woke school best feeling ever  \n",
       "1599996           thewdbcom cool hear old walt interview â  \n",
       "1599997                     ready mojo makeover ask detail  \n",
       "1599998    happy birthday boo alll time tupac amaru shakur  \n",
       "1599999        happy charitytuesday thenspcc sparkscharity  \n",
       "\n",
       "[1600000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "twit_preproc(df,'text','clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d01bc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data\n",
    "clean_df = df[['target','clean_text']]\n",
    "clean_df.to_csv('sent140_clean.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2248f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot awww thats bummer shoulda got david...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan dived many time ball managed save res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass behaving im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                         clean_text\n",
       "0       0  switchfoot awww thats bummer shoulda got david...\n",
       "1       0  upset cant update facebook texting might cry r...\n",
       "2       0  kenichan dived many time ball managed save res...\n",
       "3       0                    whole body feel itchy like fire\n",
       "4       0           nationwideclass behaving im mad cant see"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/sent140/sent140_clean.csv'\n",
    "df = pd.read_csv(path,index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127716e5",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Since our dataset is fairly large, a 2% testing set gives us 30k tweet, which is sufficient.\n",
    "We will be using cross validation to tune our model, so we only need testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12716588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df,test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0480cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1566517 rows, and testing set has 31968 rows\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "print(\"Training set has {} rows, and testing set has {} rows\".\n",
    "     format(train.shape[0],test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b4c2c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598739                                     cant fall asleep\n",
       "132635                        woke knee throbbing cant good\n",
       "747420    hostessojr ooh well update mister hahaha jk th...\n",
       "720305                                        kaceyfish aww\n",
       "288605                                        ughhh im sick\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,x_test = train['clean_text'],test['clean_text']\n",
    "y,y_test = train['target'],test['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245c7a4",
   "metadata": {},
   "source": [
    "# Vetorize\n",
    "\n",
    "I ran the same test as in notebook 1 on this new dataset and TFIDF with 10000 features and trigram gave the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1159f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=10000, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6c961ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.28662204742432\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "X = tvec.fit_transform(X)\n",
    "x_test = tvec.transform(x_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484db43",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<a id=\"4\"></a>\n",
    "As we decided in previous notebook, the model we will use is logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d54db327",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LogisticRegression(C=5e1,max_iter=1000,multi_class='multinomial',solver='lbfgs',random_state=47,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f874622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93.8 ms, sys: 60.8 ms, total: 155 ms\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlr = mlr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b99bb925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for L2\n",
      "0.7860985985985987\n"
     ]
    }
   ],
   "source": [
    "preds = mlr.predict(x_test)\n",
    "print(\"Model Accuracy for L2\")\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "941f3e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=4\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.296\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cant wait\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.294\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cannot wait\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.153\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        banksyart\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.964\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wish luck\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.719\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nothing wrong\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.641\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mileymonday\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.468\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        smiling\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.454\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        meits simple\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.414\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cant get enough\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.395\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        isnt bad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.363\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wasnt bad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.346\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        made day\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.284\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        congratulation\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.258\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sad sad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.256\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        thank\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.234\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        tell annoying\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.155\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dont sad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.139\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fair enough\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.130\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dont forget\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.097\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        honored\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.081\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        glad could\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.073\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        thanks\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.042\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dont miss\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.042\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        smile\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.039\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        proud\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.022\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        stay tuned\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.010\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        feel free\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.977\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sleep tight\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.942\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wanted say\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.907\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        blessing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.905\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        musicmonday\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.902\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        followfriday\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.892\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        blessed\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.23%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.868\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        glad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.852\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        welcome\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.840\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        love weather\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.825\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        get follower day\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.824\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        laughter\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.821\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        awesome\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.818\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        yayyy\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.813\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        congrats\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.784\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        doesnt mean\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.779\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        life good\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.770\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        limit story\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.763\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        pleasure\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.762\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        grin\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.758\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        get tired\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.748\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hehe\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.741\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        yay\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.739\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sound like plan\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.66%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 4782 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.17%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 5164 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.348\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        keep crashing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.950\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        passed away\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.221\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dont feel good\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.477\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.070\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        inaperfectworld\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(estimator=mlr, \n",
    "                  feature_names= list(tvec.get_feature_names()),\n",
    "                  top=(50,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "250abd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(C=1.0, class_weight=None, max_iter=100, multi_class='ovr',\n",
    "          penalty='l2', random_state=47, solver='liblinear',\n",
    "          verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0fc408d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 6.1 s, total: 50.3 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%timelgr = klgr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90c040e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for L2\n",
      "0.7865052552552553\n"
     ]
    }
   ],
   "source": [
    "preds = lgr.predict(x_test)\n",
    "print(\"Model Accuracy for L2\")\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd3126",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning\n",
    "\n",
    "Here we explore 2 methods that transform Logistic Regression to a multi-class classifier:\n",
    "- One-versus-Rest(OvR)\n",
    "- Softmax(Multinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f58305",
   "metadata": {},
   "source": [
    "### One Versus Rest(ovr)\n",
    "\n",
    "The question of whether a word is positive, negative or neutral will be divided into 3 problems:\n",
    "- Binary Classification1: `neutral` vs `[positive, negative]` \n",
    "- Binary Classification2: `positive` vs `[neutral, negative]` \n",
    "- Binary Classification3: `negative` vs `[positive, neutral]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0c96739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "param_dict = {\n",
    "    'C' : [1.0,0.1,0.01],\n",
    "    'penalty':['l1','l2']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71f2edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# define model\n",
    "mlgr = LogisticRegression(max_iter=1000,multi_class='ovr',solver='liblinear')\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search\n",
    "search = GridSearchCV(mlgr, param_dict, scoring='accuracy', n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5e36ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 3.86 s, total: 23.8 s\n",
      "Wall time: 12min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a06fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7848775340810589\n",
      "Best Hyperparameters: {'C': 1.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7f6e3",
   "metadata": {},
   "source": [
    "### Multinomial \n",
    "\n",
    "In multinomial approach, instead of log-odds, we measure relative log-odds. Also, instead of a shared weight, each class will have its own set of weights.\n",
    "\n",
    "Read [more](https://qr.ae/pG0T3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "77f81bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict1 = {'solver': ['saga', 'lbfgs'],\n",
    "              'penalty' :['elasticnet', 'l1', 'l2', 'none']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "51f70cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "mlgr = LogisticRegression(max_iter=500,multi_class='multinomial',C=1.0)\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search\n",
    "search = GridSearchCV(mlgr, param_dict1, scoring='accuracy', n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8aa192f1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "90 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.78487796        nan 0.78450069 0.78449431\n",
      " 0.7842728  0.78427216]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13h 39min 8s, sys: 3min 14s, total: 13h 42min 23s\n",
      "Wall time: 3d 1h 15min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e910ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for MULTINOMIAL class\n",
      "Best Score: 0.7848779596500978\n",
      "Best Hyperparameters: {'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Result for MULTINOMIAL class\")\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda6973",
   "metadata": {},
   "source": [
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator%20which%20gave%20highest%20score%20(or%20smallest%20loss%20if%20specified)%20on%20the%20left%20out%20data.) yields the final model with the best score on the left out data, so we need to retrain the model on the completed dataset again.\n",
    "\n",
    "*Note: \n",
    "- From multiple projects on the same data sets, C=1.0 yields the best result so i skipped tuning for this one.\n",
    "- I expected l1 to have better performance since it throw away unimportent features(which we have a lot), but we will do more research on this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "39151f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = LogisticRegression(max_iter=2000,multi_class='multinomial',C=1.0,penalty='l1',solver='saga',\n",
    "                                random_state=47)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2f0dff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the training and testing set\n",
    "# cancat won't work for X since it is does not support sparse matrix\n",
    "from scipy.sparse import vstack \n",
    "X_all = vstack((X,x_test))\n",
    "y_all = pd.concat([y,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7c96782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = final_lr.fit(X_all,y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c9eac",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3546b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# create an iterator object with write permission - model.pkl\n",
    "filename = 'finalized_mlr_model.sav'\n",
    "pickle.dump(final_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "169de8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "with open('finalized_mlr_model.sav' , 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e6da8af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7909471971971972"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "preds = model.predict(x_test)\n",
    "acc = accuracy_score(y_test,preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df59f0b",
   "metadata": {},
   "source": [
    "**Don't forget to SAVE YOUR VECTORIZER!!!!!** *i almost did :)))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4596a65a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cant': 1058,\n",
       " 'fall': 2512,\n",
       " 'asleep': 372,\n",
       " 'cant fall': 1074,\n",
       " 'fall asleep': 2513,\n",
       " 'cant fall asleep': 1075,\n",
       " 'woke': 9626,\n",
       " 'knee': 4728,\n",
       " 'good': 3296,\n",
       " 'ooh': 6310,\n",
       " 'well': 9450,\n",
       " 'update': 9122,\n",
       " 'mister': 5664,\n",
       " 'hahaha': 3614,\n",
       " 'jk': 4584,\n",
       " 'think': 8536,\n",
       " 'im': 4178,\n",
       " 'getting': 3059,\n",
       " 'sick': 7599,\n",
       " 'throat': 8604,\n",
       " 'hurt': 4088,\n",
       " 'think im': 8549,\n",
       " 'im getting': 4233,\n",
       " 'getting sick': 3075,\n",
       " 'throat hurt': 8605,\n",
       " 'think im getting': 8550,\n",
       " 'im getting sick': 4235,\n",
       " 'aww': 455,\n",
       " 'ughhh': 9073,\n",
       " 'im sick': 4325,\n",
       " 'got': 3399,\n",
       " 'headache': 3760,\n",
       " 'got headache': 3421,\n",
       " 'want': 9293,\n",
       " 'week': 9421,\n",
       " 'ago': 97,\n",
       " 'brit': 919,\n",
       " 'beyonce': 715,\n",
       " 'broken': 934,\n",
       " 'time': 8641,\n",
       " 'machine': 5363,\n",
       " 'week ago': 9422,\n",
       " 'view': 9204,\n",
       " 'spectacular': 7898,\n",
       " 'macbook': 5361,\n",
       " 'crashed': 1582,\n",
       " 'let': 4964,\n",
       " 'see': 7415,\n",
       " 'apple': 313,\n",
       " 'support': 8208,\n",
       " 'israel': 4481,\n",
       " 'let see': 4972,\n",
       " 'know': 4737,\n",
       " 'spain': 7883,\n",
       " 'lot': 5258,\n",
       " 'people': 6491,\n",
       " 'glad': 3108,\n",
       " 'caught': 1163,\n",
       " 'lot people': 5263,\n",
       " 'miss': 5638,\n",
       " 'best': 683,\n",
       " 'friend': 2851,\n",
       " 'fiance': 2640,\n",
       " 'goodnight': 3380,\n",
       " 'miss best': 5641,\n",
       " 'best friend': 686,\n",
       " 'believe': 666,\n",
       " 'beat': 620,\n",
       " 'bull': 972,\n",
       " 'cant believe': 1061,\n",
       " 'haha': 3591,\n",
       " 'amp': 207,\n",
       " 'tell': 8371,\n",
       " 'kid': 4695,\n",
       " 'one': 6264,\n",
       " 'hooked': 3946,\n",
       " 'lmao': 5134,\n",
       " 'hope': 3949,\n",
       " 'thing': 8515,\n",
       " 'improve': 4384,\n",
       " 'hope thing': 3984,\n",
       " 'followed': 2763,\n",
       " 'lol': 5152,\n",
       " 'last': 4840,\n",
       " 'person': 6520,\n",
       " 'could': 1516,\n",
       " 'yea': 9844,\n",
       " 'talking': 8318,\n",
       " 'always': 177,\n",
       " 'pleasure': 6638,\n",
       " 'ill': 4138,\n",
       " 'hit': 3871,\n",
       " 'get': 2970,\n",
       " 'spot': 7932,\n",
       " 'hve': 4097,\n",
       " 'sore': 7830,\n",
       " 'ugh': 9067,\n",
       " 'killin': 4704,\n",
       " 'came': 1035,\n",
       " 'outta': 6358,\n",
       " 'nowhere': 6136,\n",
       " 'sore throat': 7831,\n",
       " 'sound': 7855,\n",
       " 'like': 4998,\n",
       " 'need': 5870,\n",
       " 'sound like': 7860,\n",
       " 'like need': 5043,\n",
       " 'working': 9718,\n",
       " 'couple': 1549,\n",
       " 'project': 6799,\n",
       " 'done': 2047,\n",
       " 'asap': 359,\n",
       " 'youre': 9919,\n",
       " 'enjoying': 2336,\n",
       " 'saturday': 7329,\n",
       " 'hope youre': 3993,\n",
       " 'youre enjoying': 9925,\n",
       " 'doesnt': 2015,\n",
       " 'wanna': 9274,\n",
       " 'go': 3140,\n",
       " 'work': 9667,\n",
       " 'tomorrow': 8806,\n",
       " 'doesnt wanna': 2032,\n",
       " 'wanna go': 9278,\n",
       " 'go work': 3198,\n",
       " 'work tomorrow': 9707,\n",
       " 'wanna go work': 9281,\n",
       " 'go work tomorrow': 3200,\n",
       " 'eating': 2258,\n",
       " 'shit': 7548,\n",
       " 'suck': 8144,\n",
       " 'still': 8025,\n",
       " 'pain': 6389,\n",
       " 'mind': 5626,\n",
       " 'hi': 3844,\n",
       " 'italy': 4485,\n",
       " 'love': 5275,\n",
       " 'bone': 819,\n",
       " 'fire': 2699,\n",
       " 'ice': 4105,\n",
       " 'begin': 657,\n",
       " 'yay': 9833,\n",
       " 'yes': 9880,\n",
       " 'spamming': 7886,\n",
       " 'twitter': 9011,\n",
       " 'worst': 9737,\n",
       " 'sit': 7643,\n",
       " 'thanks': 8426,\n",
       " 'guy': 3573,\n",
       " 'thanks guy': 8438,\n",
       " 'follow': 2758,\n",
       " 'accidentally': 30,\n",
       " 'house': 4045,\n",
       " 'threw': 8602,\n",
       " 'fit': 2716,\n",
       " 'way': 9387,\n",
       " 'sure': 8214,\n",
       " 'year': 9865,\n",
       " 'back': 485,\n",
       " 'channel': 1213,\n",
       " 'even': 2382,\n",
       " 'screen': 7389,\n",
       " 'meal': 5521,\n",
       " 'meeting': 5538,\n",
       " 'last year': 4866,\n",
       " 'hey': 3833,\n",
       " 'really': 6967,\n",
       " 'help': 3818,\n",
       " 'outlook': 6354,\n",
       " 'reply': 7118,\n",
       " 'really need': 7008,\n",
       " 'need help': 5884,\n",
       " 'early': 2231,\n",
       " 'lunch': 5342,\n",
       " 'bet': 701,\n",
       " 'say': 7339,\n",
       " 'user': 9162,\n",
       " 'feeling': 2609,\n",
       " 'feeling well': 2623,\n",
       " 'banging': 572,\n",
       " 'head': 3755,\n",
       " 'wall': 9269,\n",
       " 'already': 165,\n",
       " 'sorry': 7832,\n",
       " 'leavin': 4934,\n",
       " 'discount': 1979,\n",
       " 'june': 4638,\n",
       " 'ready': 6944,\n",
       " 'battle': 601,\n",
       " 'mine': 5627,\n",
       " 'getting ready': 3069,\n",
       " 'difference': 1947,\n",
       " 'life': 4986,\n",
       " 'actually': 52,\n",
       " 'nothing': 6122,\n",
       " 'freaking': 2830,\n",
       " 'love life': 5290,\n",
       " 'im freaking': 4228,\n",
       " 'roommate': 7226,\n",
       " 'night': 6044,\n",
       " 'saw': 7337,\n",
       " 'post': 6702,\n",
       " 'sweetie': 8257,\n",
       " 'oh': 6181,\n",
       " 'morning': 5717,\n",
       " 'oh good': 6191,\n",
       " 'good morning': 3335,\n",
       " 'mean': 5522,\n",
       " 'rest': 7138,\n",
       " 'party': 6423,\n",
       " 'harder': 3691,\n",
       " 'final': 2659,\n",
       " 'movie': 5754,\n",
       " 'favorite': 2555,\n",
       " 'history': 3870,\n",
       " 'teacher': 8350,\n",
       " 'watching': 9373,\n",
       " 'titanic': 8719,\n",
       " 'except': 2447,\n",
       " 'part': 6419,\n",
       " 'old': 6243,\n",
       " 'lady': 4819,\n",
       " 'rose': 7229,\n",
       " 'telling': 8377,\n",
       " 'story': 8088,\n",
       " 'jack': 4530,\n",
       " 'dy': 2218,\n",
       " 'like old': 5046,\n",
       " 'old lady': 6246,\n",
       " 'finally': 2664,\n",
       " 'yay finally': 9835,\n",
       " 'wanted': 9333,\n",
       " 'come': 1389,\n",
       " 'ashleytisdale': 363,\n",
       " 'wish': 9584,\n",
       " 'live': 5124,\n",
       " 'ny': 6151,\n",
       " 'pls': 6641,\n",
       " 'second': 7410,\n",
       " 'single': 7635,\n",
       " 'wish could': 9586,\n",
       " 'using': 9164,\n",
       " 'api': 303,\n",
       " 'using twitter': 9167,\n",
       " 'melissa': 5548,\n",
       " 'rock': 7203,\n",
       " 'world': 9729,\n",
       " 'depends': 1867,\n",
       " 'fun': 2894,\n",
       " 'woo': 9653,\n",
       " 'tired': 8706,\n",
       " 'ttyl': 8958,\n",
       " 'take': 8286,\n",
       " 'care': 1138,\n",
       " 'god': 3204,\n",
       " 'bless': 777,\n",
       " 'everyone': 2415,\n",
       " 'pray': 6728,\n",
       " 'good night': 3343,\n",
       " 'take care': 8289,\n",
       " 'god bless': 3205,\n",
       " 'melting': 5551,\n",
       " 'heat': 3787,\n",
       " 'playing': 6609,\n",
       " 'gear': 2954,\n",
       " 'certainly': 1194,\n",
       " 'didnt': 1910,\n",
       " 'shut': 7595,\n",
       " 'online': 6306,\n",
       " 'personally': 6523,\n",
       " 'pretty': 6750,\n",
       " 'busy': 994,\n",
       " 'hour': 4027,\n",
       " 'im pretty': 4306,\n",
       " 'xx': 9815,\n",
       " 'dane': 1685,\n",
       " 'cook': 1487,\n",
       " 'hilarious': 3862,\n",
       " 'dane cook': 1686,\n",
       " 'pizza': 6588,\n",
       " 'hanging': 3647,\n",
       " 'tonight': 8832,\n",
       " 'family': 2523,\n",
       " 'dad': 1665,\n",
       " 'leaf': 4915,\n",
       " 'dream': 2161,\n",
       " 'true': 8931,\n",
       " 'disney': 1990,\n",
       " 'dream come': 2162,\n",
       " 'come true': 1402,\n",
       " 'dream come true': 2163,\n",
       " 'english': 2328,\n",
       " 'thesis': 8507,\n",
       " 'talk': 8312,\n",
       " 'finished': 2693,\n",
       " 'need talk': 5903,\n",
       " 'add': 60,\n",
       " 'said': 7300,\n",
       " 'ask': 368,\n",
       " 'please': 6615,\n",
       " 'celebrity': 1179,\n",
       " 'probably': 6778,\n",
       " 'de': 1808,\n",
       " 'havent': 3724,\n",
       " 'put': 6851,\n",
       " 'new': 5948,\n",
       " 'book': 826,\n",
       " 'yet': 9893,\n",
       " 'try': 8937,\n",
       " 'end': 2316,\n",
       " 'sad': 7269,\n",
       " 'neighbor': 5912,\n",
       " 'moving': 5761,\n",
       " 'away': 437,\n",
       " 'still havent': 8045,\n",
       " 'new book': 5951,\n",
       " 'ill try': 4170,\n",
       " 'character': 1217,\n",
       " 'work ill': 9685,\n",
       " 'ill tell': 4169,\n",
       " 'awww': 465,\n",
       " 'ur': 9142,\n",
       " 'went': 9494,\n",
       " 'wknd': 9619,\n",
       " 'first': 2703,\n",
       " 'web': 9413,\n",
       " 'service': 7493,\n",
       " 'ive': 4500,\n",
       " 'bit': 756,\n",
       " 'confused': 1459,\n",
       " 'regarding': 7068,\n",
       " 'language': 4834,\n",
       " 'use': 9156,\n",
       " 'farrah': 2540,\n",
       " 'passed': 6433,\n",
       " 'updating': 9125,\n",
       " 'itunes': 4495,\n",
       " 'ipod': 4458,\n",
       " 'may': 5496,\n",
       " 'awhile': 452,\n",
       " 'chocolate': 1281,\n",
       " 'american': 203,\n",
       " 'appreciate': 320,\n",
       " 'name': 5834,\n",
       " 'look': 5209,\n",
       " 'nice': 6015,\n",
       " 'laid': 4823,\n",
       " 'look nice': 5221,\n",
       " 'isnt': 4472,\n",
       " 'every': 2402,\n",
       " 'day': 1716,\n",
       " 'sunday': 8187,\n",
       " 'every day': 2403,\n",
       " 'hello': 3812,\n",
       " 'monday': 5694,\n",
       " 'dont': 2052,\n",
       " 'forget': 2790,\n",
       " 'read': 6936,\n",
       " 'blog': 790,\n",
       " 'yesterday': 9891,\n",
       " 'there': 8498,\n",
       " 'coming': 1410,\n",
       " 'today': 8729,\n",
       " 'dont forget': 2069,\n",
       " 'read blog': 6937,\n",
       " 'new one': 5971,\n",
       " 'tried': 8924,\n",
       " 'laying': 4902,\n",
       " 'kept': 4683,\n",
       " 'everybody': 2413,\n",
       " 'fell': 2624,\n",
       " 'transformer': 8898,\n",
       " 'cute': 1651,\n",
       " 'fell asleep': 2625,\n",
       " 'must': 5814,\n",
       " 'hw': 4098,\n",
       " 'job': 4586,\n",
       " 'test': 8396,\n",
       " 'study': 8124,\n",
       " 'dont time': 2104,\n",
       " 'thats': 8458,\n",
       " 'sooo': 7810,\n",
       " 'exciting': 2455,\n",
       " 'learned': 4921,\n",
       " 'buy': 1004,\n",
       " 'paint': 6391,\n",
       " 'tweet': 8983,\n",
       " 'jean': 4561,\n",
       " 'reminds': 7103,\n",
       " 'weekend': 9436,\n",
       " 'bought': 861,\n",
       " 'something': 7776,\n",
       " 'cool': 1493,\n",
       " 'ignore': 4129,\n",
       " 'twit': 9006,\n",
       " 'later': 4875,\n",
       " 'lmfao': 5136,\n",
       " 'nah': 5829,\n",
       " 'heap': 3774,\n",
       " 'gotta': 3450,\n",
       " 'find': 2676,\n",
       " 'hehe': 3801,\n",
       " 'im sure': 4346,\n",
       " 'found': 2808,\n",
       " 'straight': 8091,\n",
       " 'looking': 5228,\n",
       " 'setting': 7497,\n",
       " 'might': 5598,\n",
       " 'tempted': 8382,\n",
       " 'pro': 6776,\n",
       " 'version': 9192,\n",
       " 'missing': 5659,\n",
       " 'argentina': 336,\n",
       " 'much': 5775,\n",
       " 'soon': 7804,\n",
       " 'come back': 1390,\n",
       " 'back soon': 510,\n",
       " 'come back soon': 1391,\n",
       " 'joy': 4624,\n",
       " 'heavy': 3791,\n",
       " 'man': 5437,\n",
       " 'fawcett': 2560,\n",
       " 'oh man': 6202,\n",
       " 'farrah fawcett': 2541,\n",
       " 'passed away': 6434,\n",
       " 'victory': 9198,\n",
       " 'ave': 423,\n",
       " 'store': 8085,\n",
       " 'fucking': 2886,\n",
       " 'awesome': 439,\n",
       " 'computer': 1439,\n",
       " 'sync': 8273,\n",
       " 'everything': 2427,\n",
       " 'grumpy': 3546,\n",
       " 'make': 5389,\n",
       " 'make sad': 5412,\n",
       " 'thing go': 8522,\n",
       " 'go well': 3197,\n",
       " 'thinking': 8572,\n",
       " 'bout': 865,\n",
       " 'nothing much': 6126,\n",
       " 'flat': 2728,\n",
       " 'tire': 8705,\n",
       " 'way early': 9390,\n",
       " 'word': 9664,\n",
       " 'bad': 529,\n",
       " 'enough': 2338,\n",
       " 'co': 1357,\n",
       " 'plastic': 6599,\n",
       " 'sun': 8175,\n",
       " 'would': 9746,\n",
       " 'stay': 7992,\n",
       " 'rain': 6895,\n",
       " 'next': 5996,\n",
       " 'look like': 5217,\n",
       " 'like rain': 5050,\n",
       " 'next week': 6008,\n",
       " 'alright': 170,\n",
       " 'ahhhh': 111,\n",
       " 'rum': 7251,\n",
       " 'cake': 1021,\n",
       " 'yum': 9963,\n",
       " 'downloading': 2139,\n",
       " 'iphone': 4454,\n",
       " 'right': 7176,\n",
       " 'wait': 9240,\n",
       " 'till': 8635,\n",
       " 'finish': 2691,\n",
       " 'phone': 6539,\n",
       " 'currently': 1643,\n",
       " 'call': 1026,\n",
       " 'almost': 156,\n",
       " 'new iphone': 5965,\n",
       " 'right cant': 7178,\n",
       " 'cant wait': 1115,\n",
       " 'wait till': 9251,\n",
       " 'cant wait till': 1123,\n",
       " 'twittered': 9035,\n",
       " 'happens': 3657,\n",
       " 'indeed': 4397,\n",
       " 'create': 1590,\n",
       " 'amazing': 192,\n",
       " 'beautiful': 623,\n",
       " 'pastor': 6445,\n",
       " 'made': 5365,\n",
       " 'wrong': 9796,\n",
       " 'someone': 7768,\n",
       " 'bed': 635,\n",
       " 'aha': 103,\n",
       " 'tennis': 8386,\n",
       " 'one day': 6267,\n",
       " 'day ill': 1750,\n",
       " 'ill get': 4148,\n",
       " 'get one': 3018,\n",
       " 'ill talk': 4168,\n",
       " 'talk later': 8314,\n",
       " 'staying': 8002,\n",
       " 'home': 3899,\n",
       " 'weather': 9408,\n",
       " 'sucky': 8150,\n",
       " 'staying home': 8003,\n",
       " 'creep': 1598,\n",
       " 'gorgeous': 3393,\n",
       " 'nyc': 6152,\n",
       " 'gonna': 3272,\n",
       " 'lay': 4900,\n",
       " 'outside': 6355,\n",
       " 'learn': 4920,\n",
       " 'script': 7393,\n",
       " 'short': 7565,\n",
       " 'film': 2656,\n",
       " 'audition': 406,\n",
       " 'scared': 7363,\n",
       " 'gorgeous day': 3394,\n",
       " 'im scared': 4321,\n",
       " 'sure im': 8218,\n",
       " 'im ready': 4312,\n",
       " 'jonasbrothers': 4613,\n",
       " 'release': 7086,\n",
       " 'australian': 415,\n",
       " 'date': 1703,\n",
       " 'feel': 2573,\n",
       " 'left': 4943,\n",
       " 'jealous': 4560,\n",
       " 'feel left': 2585,\n",
       " 'nooooo': 6108,\n",
       " 'baby': 477,\n",
       " 'he': 3748,\n",
       " 'leg': 4947,\n",
       " 'damn': 1674,\n",
       " 'afternoon': 90,\n",
       " 'nap': 5839,\n",
       " 'wife': 9555,\n",
       " 'good afternoon': 3297,\n",
       " 'throw': 8607,\n",
       " 'nothin': 6121,\n",
       " 'everyday': 2414,\n",
       " 'rich': 7167,\n",
       " 'chef': 1249,\n",
       " 'jet': 4578,\n",
       " 'expectation': 2465,\n",
       " 'still go': 8040,\n",
       " 'judge': 4628,\n",
       " 'sweet': 8252,\n",
       " 'youre sweet': 9942,\n",
       " 'best day': 685,\n",
       " 'day today': 1784,\n",
       " 'taking': 8304,\n",
       " 'bath': 596,\n",
       " 'reading': 6941,\n",
       " 'bros': 937,\n",
       " 'show': 7576,\n",
       " 'one best': 6265,\n",
       " 'best show': 691,\n",
       " 'missed': 5656,\n",
       " 'red': 7055,\n",
       " 'many': 5455,\n",
       " 'drop': 2181,\n",
       " 'blackberry': 767,\n",
       " 'many time': 5458,\n",
       " 'sm': 7709,\n",
       " 'soul': 7853,\n",
       " 'want get': 9300,\n",
       " 'aw': 427,\n",
       " 'beta': 702,\n",
       " 'game': 2933,\n",
       " 'wait get': 9243,\n",
       " 'cant wait get': 1116,\n",
       " 'school': 7371,\n",
       " 'half': 3629,\n",
       " 'really wish': 7029,\n",
       " 'hate': 3702,\n",
       " 'wasnt': 9352,\n",
       " 'impressed': 4381,\n",
       " 'great': 3490,\n",
       " 'concept': 1443,\n",
       " 'friend mine': 2859,\n",
       " 'unfortunately': 9104,\n",
       " 'spell': 7902,\n",
       " 'spelling': 7904,\n",
       " 'little': 5108,\n",
       " 'never': 5929,\n",
       " 'thank': 8413,\n",
       " 'hey im': 3838,\n",
       " 'im actually': 4179,\n",
       " 'pretty good': 6755,\n",
       " 'thank god': 8417,\n",
       " 'yeah': 9846,\n",
       " 'okay': 6239,\n",
       " 'trouble': 8929,\n",
       " 'jake': 4539,\n",
       " 'going': 3214,\n",
       " 'graduate': 3469,\n",
       " 'high': 3851,\n",
       " 'yeah im': 9851,\n",
       " 'im okay': 4301,\n",
       " 'okay im': 6241,\n",
       " 'much im': 5782,\n",
       " 'im going': 4240,\n",
       " 'going miss': 3245,\n",
       " 'high school': 3852,\n",
       " 'im going miss': 4246,\n",
       " 'far': 2532,\n",
       " 'though': 8586,\n",
       " 'far away': 2533,\n",
       " 'sound nice': 7865,\n",
       " 'kitten': 4722,\n",
       " 'drag': 2147,\n",
       " 'hell': 3808,\n",
       " 'sam': 7313,\n",
       " 'drag hell': 2148,\n",
       " 'run': 7253,\n",
       " 'giggle': 3088,\n",
       " 'supposed': 8211,\n",
       " 'rough': 7232,\n",
       " 'iâ': 4526,\n",
       " 'sleepy': 7694,\n",
       " 'sleep': 7668,\n",
       " 'came back': 1036,\n",
       " 'back school': 507,\n",
       " 'got time': 3444,\n",
       " 'time sleep': 8676,\n",
       " 'ditto': 1999,\n",
       " 'youuuu': 9952,\n",
       " 'play': 6602,\n",
       " 'delicious': 1848,\n",
       " 'burger': 982,\n",
       " 'grill': 3528,\n",
       " 'tom': 8794,\n",
       " 'fb': 2561,\n",
       " 'ol': 6242,\n",
       " 'low': 5331,\n",
       " 'ticket': 8623,\n",
       " 'argh': 337,\n",
       " 'going bed': 3220,\n",
       " 'time low': 8668,\n",
       " 'strep': 8100,\n",
       " 'cause': 1164,\n",
       " 'town': 8877,\n",
       " 'mad': 5364,\n",
       " 'plan': 6592,\n",
       " 'bbq': 607,\n",
       " 'cause im': 1167,\n",
       " 'mileycyrus': 5614,\n",
       " 'luv': 5349,\n",
       " 'wait see': 9249,\n",
       " 'cant wait see': 1121,\n",
       " 'jay': 4555,\n",
       " 'cuz': 1656,\n",
       " 'real': 6956,\n",
       " 'excited': 2450,\n",
       " 'long': 5194,\n",
       " 'beach': 613,\n",
       " 'sytycd': 8276,\n",
       " 'used': 9158,\n",
       " 'im sad': 4319,\n",
       " 'gold': 3266,\n",
       " 'downstairs': 2142,\n",
       " 'ac': 23,\n",
       " 'seem': 7453,\n",
       " 'reset': 7127,\n",
       " 'hoping': 4000,\n",
       " 'upstairs': 9141,\n",
       " 'doesnt seem': 2030,\n",
       " 'mo': 5676,\n",
       " 'didnt think': 1936,\n",
       " 'think like': 8555,\n",
       " 'least': 4924,\n",
       " 'face': 2495,\n",
       " 'least get': 4925,\n",
       " 'get see': 3032,\n",
       " 'amber': 200,\n",
       " 'distance': 1995,\n",
       " 'huhu': 4067,\n",
       " 'aku': 130,\n",
       " 'whats': 9513,\n",
       " 'whats wrong': 9518,\n",
       " 'following': 2770,\n",
       " 'youve': 9953,\n",
       " 'taken': 8302,\n",
       " 'btw': 953,\n",
       " 'hows': 4054,\n",
       " 'seen': 7459,\n",
       " 'shoot': 7558,\n",
       " 'girl': 3092,\n",
       " 'say im': 7350,\n",
       " 'im back': 4189,\n",
       " 'bnp': 805,\n",
       " 'radio': 6891,\n",
       " 'sounded': 7867,\n",
       " 'minute': 5632,\n",
       " 'train': 8891,\n",
       " 'babe': 476,\n",
       " 'hug': 4062,\n",
       " 'called': 1029,\n",
       " 'leo': 4959,\n",
       " 'cmon': 1354,\n",
       " 'hour left': 4037,\n",
       " 'heyy': 3842,\n",
       " 'thrilled': 8603,\n",
       " 'teen': 8364,\n",
       " 'choice': 1284,\n",
       " 'award': 434,\n",
       " 'teen choice': 8365,\n",
       " 'choice award': 1285,\n",
       " 'donniewahlberg': 2051,\n",
       " 'reason': 7032,\n",
       " 'mistake': 5663,\n",
       " 'change': 1210,\n",
       " 'roll': 7215,\n",
       " 'bring': 913,\n",
       " 'bike': 733,\n",
       " 'stair': 7958,\n",
       " 'like time': 5061,\n",
       " 'funny': 2916,\n",
       " 'tv': 8977,\n",
       " 'sometimes': 7785,\n",
       " 'sean': 7399,\n",
       " 'bean': 616,\n",
       " 'heart': 3781,\n",
       " 'via': 9194,\n",
       " 'event': 2394,\n",
       " 'control': 1480,\n",
       " 'fault': 2550,\n",
       " 'itll': 4492,\n",
       " 'complicated': 1437,\n",
       " 'hah': 3590,\n",
       " 'yeah love': 9855,\n",
       " 'sucking': 8149,\n",
       " 'egg': 2284,\n",
       " 'life good': 4987,\n",
       " 'cycle': 1660,\n",
       " 'link': 5088,\n",
       " 'ooc': 6309,\n",
       " 'whoop': 9543,\n",
       " 'ok': 6230,\n",
       " 'yall': 9829,\n",
       " 'command': 1415,\n",
       " 'question': 6859,\n",
       " 'trip': 8926,\n",
       " 'sister': 7642,\n",
       " 'thunder': 8614,\n",
       " 'dog': 2036,\n",
       " 'crazy': 1587,\n",
       " 'leave': 4930,\n",
       " 'really want': 7023,\n",
       " 'want go': 9302,\n",
       " 'going crazy': 3224,\n",
       " 'cant leave': 1089,\n",
       " 'day long': 1757,\n",
       " 'really want go': 7024,\n",
       " 'answered': 276,\n",
       " 'du': 2193,\n",
       " 'wale': 9263,\n",
       " 'lovely': 5323,\n",
       " 'load': 5138,\n",
       " 'easy': 2251,\n",
       " 'stuff': 8128,\n",
       " 'back online': 504,\n",
       " 'storm': 8086,\n",
       " 'cutting': 1655,\n",
       " 'power': 6720,\n",
       " 'main': 5384,\n",
       " 'stage': 7957,\n",
       " 'audience': 404,\n",
       " 'singing': 7634,\n",
       " 'along': 161,\n",
       " 'anyway': 296,\n",
       " 'summer': 8165,\n",
       " 'ball': 562,\n",
       " 'thunder storm': 8615,\n",
       " 'love summer': 5309,\n",
       " 'peep': 6485,\n",
       " 'wot': 9745,\n",
       " 'hav': 3723,\n",
       " 'watched': 9371,\n",
       " 'vids': 9203,\n",
       " 'bak': 555,\n",
       " 'plz': 6646,\n",
       " 'follower': 2764,\n",
       " 'thnx': 8579,\n",
       " 'plz plz': 6647,\n",
       " 'need follower': 5878,\n",
       " 'totally': 8864,\n",
       " 'agree': 98,\n",
       " 'totally agree': 8865,\n",
       " 'ah': 100,\n",
       " 'nevermind': 5947,\n",
       " 'parent': 6414,\n",
       " 'fighting': 2646,\n",
       " 'fantastic': 2529,\n",
       " 'wake': 9259,\n",
       " 'bestest': 697,\n",
       " 'ever': 2396,\n",
       " 'twittering': 9040,\n",
       " 'apple store': 314,\n",
       " 'solve': 7763,\n",
       " 'image': 4373,\n",
       " 'issue': 4482,\n",
       " 'crap': 1578,\n",
       " 'hot': 4012,\n",
       " 'hot today': 4018,\n",
       " 'today dont': 8736,\n",
       " 'dont like': 2079,\n",
       " 'brad': 879,\n",
       " 'win': 9567,\n",
       " 'hand': 3640,\n",
       " 'headed': 3761,\n",
       " 'ya': 9819,\n",
       " 'better': 705,\n",
       " 'feel better': 2576,\n",
       " 'jared': 4550,\n",
       " 'arrived': 350,\n",
       " 'died': 1942,\n",
       " 'anyone': 287,\n",
       " 'cheap': 1232,\n",
       " 'office': 6173,\n",
       " 'anyone know': 289,\n",
       " 'know find': 4748,\n",
       " 'car': 1133,\n",
       " 'victim': 9196,\n",
       " 'bird': 745,\n",
       " 'severe': 7503,\n",
       " 'took': 8845,\n",
       " 'thought': 8591,\n",
       " 'happen': 3653,\n",
       " 'today really': 8768,\n",
       " 'thought going': 8592,\n",
       " 'going happen': 3237,\n",
       " 'without': 9615,\n",
       " 'dress': 2168,\n",
       " 'smart': 7713,\n",
       " 'every time': 2410,\n",
       " 'hols': 3895,\n",
       " 'big': 724,\n",
       " 'making': 5428,\n",
       " 'cold': 1373,\n",
       " 'north': 6114,\n",
       " 'nice see': 6025,\n",
       " 'littlefletcher': 5123,\n",
       " 'carrie': 1146,\n",
       " 'math': 5489,\n",
       " 'xxx': 9816,\n",
       " 'test tomorrow': 8398,\n",
       " 'im gonna': 4252,\n",
       " 'math test': 5491,\n",
       " 'fixing': 2722,\n",
       " 'bug': 966,\n",
       " 'boy': 873,\n",
       " 'quot': 6868,\n",
       " 'smile': 7720,\n",
       " 'awh': 451,\n",
       " 'cry': 1619,\n",
       " 'answer': 274,\n",
       " 'year old': 9868,\n",
       " 'made cry': 5366,\n",
       " 'best part': 690,\n",
       " 'started': 7981,\n",
       " 'crappy': 1579,\n",
       " 'laker': 4825,\n",
       " 'free': 2833,\n",
       " 'dinner': 1956,\n",
       " 'happy': 3662,\n",
       " 'day started': 1774,\n",
       " 'make happy': 5403,\n",
       " 'sleeping': 7691,\n",
       " 'laptop': 4837,\n",
       " 'station': 7988,\n",
       " 'replace': 7113,\n",
       " 'keyboard': 4687,\n",
       " 'key': 4686,\n",
       " 'got one': 3434,\n",
       " 'feelin': 2608,\n",
       " 'tummy': 8965,\n",
       " 'tummy hurt': 8967,\n",
       " 'utterly': 9170,\n",
       " 'ridiculous': 7173,\n",
       " 'dollar': 2042,\n",
       " 'burned': 984,\n",
       " 'roof': 7223,\n",
       " 'mouth': 5750,\n",
       " 'cleaning': 1323,\n",
       " 'creative': 1593,\n",
       " 'want make': 9315,\n",
       " 'always make': 184,\n",
       " 'make smile': 5415,\n",
       " 'arse': 353,\n",
       " 'near': 5863,\n",
       " 'buzz': 1009,\n",
       " 'wire': 9579,\n",
       " 'season': 7402,\n",
       " 'oh god': 6190,\n",
       " 'kind': 4708,\n",
       " 'horribly': 4005,\n",
       " 'suppose': 8210,\n",
       " 'attempt': 394,\n",
       " 'fruit': 2871,\n",
       " 'shave': 7529,\n",
       " 'didnt see': 1931,\n",
       " 'lil': 5075,\n",
       " 'sara': 7323,\n",
       " 'dave': 1706,\n",
       " 'hour work': 4044,\n",
       " 'work next': 9694,\n",
       " 'changing': 1212,\n",
       " 'bt': 952,\n",
       " 'atm': 390,\n",
       " 'waiting': 9256,\n",
       " 'itchy': 4488,\n",
       " 'make go': 5399,\n",
       " 'go away': 3144,\n",
       " 'crc': 1588,\n",
       " 'ebassman': 2263,\n",
       " 'hungry': 4080,\n",
       " 'who': 9531,\n",
       " 'ignoring': 4131,\n",
       " 'coursework': 1556,\n",
       " 'write': 9791,\n",
       " 'arent': 334,\n",
       " 'classmate': 1316,\n",
       " 'first day': 2704,\n",
       " 'day lol': 1756,\n",
       " 'stupid': 8133,\n",
       " 'internet': 4442,\n",
       " 'closed': 1341,\n",
       " 'claim': 1308,\n",
       " 'wtf': 9798,\n",
       " 'dwighthoward': 2217,\n",
       " 'ha': 3582,\n",
       " 'cried': 1603,\n",
       " 'silly': 7615,\n",
       " 'superman': 8204,\n",
       " 'men': 5558,\n",
       " 'com': 1385,\n",
       " 'din': 1953,\n",
       " 'un': 9089,\n",
       " 'familiar': 2522,\n",
       " 'ho': 3881,\n",
       " 'sent': 7479,\n",
       " 'pay': 6461,\n",
       " 'vip': 9211,\n",
       " 'get follower': 2991,\n",
       " 'follower day': 2765,\n",
       " 'day using': 1787,\n",
       " 'using add': 9165,\n",
       " 'add everyone': 61,\n",
       " 'everyone train': 2424,\n",
       " 'train pay': 8892,\n",
       " 'pay vip': 6463,\n",
       " 'get follower day': 2992,\n",
       " 'follower day using': 2766,\n",
       " 'day using add': 1788,\n",
       " 'using add everyone': 9166,\n",
       " 'add everyone train': 62,\n",
       " 'everyone train pay': 2425,\n",
       " 'train pay vip': 8893,\n",
       " 'heading': 3764,\n",
       " 'cali': 1024,\n",
       " 'jam': 4540,\n",
       " 'la': 4809,\n",
       " 'peace': 6474,\n",
       " 'amsterdam': 223,\n",
       " 'crew': 1600,\n",
       " 'heading back': 3765,\n",
       " 'back la': 496,\n",
       " 'start': 7971,\n",
       " 'til': 8632,\n",
       " 'save': 7334,\n",
       " 'blessing': 780,\n",
       " 'depressing': 1869,\n",
       " 'welcome': 9445,\n",
       " 'ur welcome': 9146,\n",
       " 'account': 34,\n",
       " 'dear': 1814,\n",
       " 'xoxo': 9811,\n",
       " 'new twitter': 5985,\n",
       " 'twitter account': 9012,\n",
       " 'dont know': 2074,\n",
       " 'know one': 4770,\n",
       " 'one love': 6284,\n",
       " 'love see': 5306,\n",
       " 'listing': 5105,\n",
       " 'music': 5809,\n",
       " 'kinda': 4710,\n",
       " 'bored': 842,\n",
       " 'home day': 3906,\n",
       " 'gosh': 3395,\n",
       " 'birthday': 748,\n",
       " 'goin': 3212,\n",
       " 'camping': 1042,\n",
       " 'gunna': 3569,\n",
       " 'wasted': 9360,\n",
       " 'including': 4393,\n",
       " 'luck': 5336,\n",
       " 'oh gosh': 6193,\n",
       " 'day im': 1751,\n",
       " 'im goin': 4239,\n",
       " 'wish luck': 9600,\n",
       " 'congratulation': 1462,\n",
       " 'america': 202,\n",
       " ...}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save trained vectorizor \n",
    "pickle.dump(tvec.vocabulary_,open(\"tvec_vocabulary.pkl\",\"wb\"))\n",
    "\n",
    "# to reuse it:\n",
    "#loaded_vec = TFIDFVectorizor(decode_error=\"replace\",vocabulary=pickle.load(open(\"tvec_vocabulary.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion waiting to be added...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
